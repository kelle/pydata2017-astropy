{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The astropy [Table](http://docs.astropy.org/en/stable/table/index.html) class provides an extension of NumPy structured arrays for storing and manipulating heterogeneous tables of data. A few notable features of this package are:\n",
    "\n",
    "- Initialize a table from a wide variety of input data structures and types.\n",
    "- Modify a table by adding or removing columns, changing column names, or adding new rows of data.\n",
    "- Handle tables containing missing values.\n",
    "- Include table and column metadata as flexible data structures.\n",
    "- Specify a description, units and output formatting for columns.\n",
    "- Perform operations like database joins, concatenation, and grouping.\n",
    "- Manipulate multidimensional columns.\n",
    "- Methods for Reading and writing Table objects to files\n",
    "- Integration with Astropy [Units and Quantities](http://astropy.readthedocs.org/en/stable/units/index.html)\n",
    "\n",
    "Tables vs. Pandas DataFrames\n",
    "--------------\n",
    "\n",
    "The [Pandas](http://pandas.pydata.org/pandas-docs/stable/) package provides a powerful, high-performance table object via the [DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html#pandas.DataFrame) class.  Unfortunately, there are a few shortcomings that prevent its use as a generalized table object in astronomy.  The most crucial is lack of support for multidimensional table columns.  This is commonly used in standard FITS data products, for instance the Chandra energy response matrix used to analyze spectral data.  Pandas DataFrame functionality is still very complementary to astropy Tables so astropy 1.1 and later provides interfaces for converting between astropy Tables and DataFrames. If you wish to learn more about Pandas, there are many resources available on-line.  A good starting point is the main tutorials site at http://pandas.pydata.org/pandas-docs/stable/tutorials.html.\n",
    "\n",
    "Documentation\n",
    "-------------\n",
    "\n",
    "For more information about the features presented below, you can read the\n",
    "[astropy.table](http://docs.astropy.org/en/stable/table/index.html) docs.\n",
    "\n",
    "*****\n",
    "*****\n",
    "\n",
    "Tutorial\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from astropy.table import Table\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import style\n",
    "style.use('ggplot')  \n",
    "matplotlib.use('nbagg')  # required for interactive plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tables\n",
    "---------------\n",
    "\n",
    "There is great deal of flexibility in the way that a table can be initially constructed:\n",
    "\n",
    "- Read an existing table from a file or web URL\n",
    "- Add columns of data one by one\n",
    "- Add rows of data one by one\n",
    "- From an existing data structure in memory:\n",
    "\n",
    "  - List of data columns\n",
    "  - Dict of data columns\n",
    "  - List of row dicts\n",
    "  - Numpy homgeneous array or structured array\n",
    "  - List of row records\n",
    "  \n",
    "See the documentation section on [Constructing a table](http://astropy.readthedocs.org/en/stable/table/construct_table.html) for the gory details and plenty of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = Table()\n",
    "t['name'] = ['larry', 'curly', 'moe', 'shemp']\n",
    "t['flux'] = [1.2, 2.2, 3.1, 4.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at your table\n",
    "\n",
    "In IPython notebook, showing a table will produce a nice HTML representation of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did the same in a terminal session you get a different view that isn't as pretty but does give a bit more information about the table:\n",
    "\n",
    "    >>> t\n",
    "    <Table rows=4 names=('name','flux')>\n",
    "    array([('source 1', 1.2), ('source 2', 2.2), ('source 3', 3.1),\n",
    "           ('source 4', 4.3)], \n",
    "          dtype=[('name', 'S8'), ('flux', '<f8')])\n",
    "\n",
    "To get a plain view which is the same in notebook and terminal use `print()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the table column names and data types using the `colnames` and `dtype` properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Astropy 1.1 and later provides a ``show_in_notebook()`` method that allows more interactive exploration of tables. It can be especially handy for large tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing parts of the table\n",
    "\n",
    "We can access the columns and rows as for numpy structured arrays.  Notice that the outputs are `Column`, `Row` or `Table` objects depending on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t['flux']  # Flux column (notice meta attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t['flux'][1]  # Row 1 of flux column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[1]  # Row obj for with row 1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[1]['flux']  # Flux column of row 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[1:3]  # 2nd and 3rd rows in a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t[[1, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One of the most powerful concepts is using boolean selection masks to filter tables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = t['flux'] > 3.0  # Define boolean mask for all flux values > 3\n",
    "t[mask]  # Create a new table with only the \"high flux\" sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the table\n",
    "\n",
    "Once the table exists with defined columns there are a number of ways to modify the table in place.  These are fully documented in the section [Modifying a Table](http://astropy.readthedocs.org/en/stable/table/modify_table.html#modifying-a-table).\n",
    "\n",
    "To give a couple of simple examples, you can add rows with the [add_row()](http://astropy.readthedocs.org/en/stable/api/astropy.table.Table.html#astropy.table.Table.add_row) method or add new columns using dict-style assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t.add_row(('joe', 10.1))  # Add a new source at the end\n",
    "t['logflux'] = np.log10(t['flux'])  # Compute the log10 of the flux\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `logflux` column really has too many output digits given the precision of the input values.  We can fix this by setting the format using normal Python formatting syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t['flux'].format = '%.2f'\n",
    "t['logflux'].format = '%.2f'\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the table to numpy\n",
    "\n",
    "Sometimes you may not want or be able to use a `Table` object and prefer to work with a plain numpy array.  This is easily done by passing the table to the `np.array()` constructor.  \n",
    "\n",
    "*This makes a copy of the data*.  If you have a huge table and don't want to waste memory, supply `copy=False` to the constructor, but be warned that changing the output numpy array will change the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masked tables\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2 = Table([['x', 'y', 'z'], \n",
    "            [1.1, 2.2, 3.3]],\n",
    "           names=['name', 'value'],\n",
    "           masked=True)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2['value'].mask = [False, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2['value'].fill_value = -99\n",
    "print(t2.filled())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-level table operations\n",
    "----------------------------\n",
    "\n",
    "So far we've just worked with one table at a time and viewed that table as a monolithic entity.  Astropy also supports high-level [Table operations](http://astropy.readthedocs.org/en/stable/table/operations.html) that manipulate multiple tables or view one table as a collection of sub-tables (groups).\n",
    "\n",
    " Documentation\t                                                                         | Description\n",
    "---------------------------------------------------------------------------------------- |-----------------------------------------\n",
    "[Grouped operations](http://astropy.readthedocs.org/en/stable/table/operations.html#id2) | Group tables and columns by keys\n",
    "[Stack vertically](http://astropy.readthedocs.org/en/stable/table/operations.html#id3)   | Concatenate input tables along rows\n",
    "[Stack horizontally](http://astropy.readthedocs.org/en/stable/table/operations.html#id4) | Concatenate input tables along columns\n",
    "[Join](http://astropy.readthedocs.org/en/stable/table/operations.html#join)              | Database-style join of two tables\n",
    "\n",
    "Here we'll just introduce the join operation but go into more detail on the others in the exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy.table import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recall our original table `t`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say that we now got some additional flux values from a different reference for a different, but overlapping sample of sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2 = Table()\n",
    "t2['name'] = ['larry', 'moe', 'groucho']\n",
    "t2['flux2'] = [1.4, 3.5, 8.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get a master table of flux measurements which are joined matching the values the `name` column.  This includes every row from each of the two tables, which is known as an **`outer`** join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t3 = join(t, t2, keys=['name'], join_type='outer')\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(t3['flux2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately we could choose to keep only rows where both tables had a valid measurement using an **`inner`** join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join(t, t2, keys=['name'], join_type='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t3.write('test.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t3.write('test.vot', format='votable', overwrite=True)\n",
    "!more test.vot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data\n",
    "------------\n",
    "\n",
    "You can read data using the [Table.read()](http://astropy.readthedocs.org/en/stable/api/astropy.table.Table.html#astropy.table.Table.read) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t4 = Table.read('test.fits')\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some formats, such as FITS and HDF5, are automatically identified by file extention while most others will require ``format`` to be explicitly provided. A number of common ascii formats are supported such as IPAC, sextractor, daophot, and CSV. Refer to the documentation for a full listing.  More details about this are also in the final sections of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Table.read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head 2mass.tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_2mass = Table.read(\"2mass.tbl\", format=\"ascii.ipac\")\n",
    "t_2mass.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pandas\n",
    "Astropy tables includes  `to_pandas()` and `from_pandas()` [methods](http://docs.astropy.org/en/stable/table/pandas.html)  that facilitate conversion to/from [pandas](http://pandas.pydata.org) `DataFrame` objects.  There are a few caveats in making these conversions:\n",
    " - Tables with multi-dimensional columns cannot be converted.\n",
    " - Masked values are converted to `numpy.nan`. Numerical columns, int or float, are thus converted to ``numpy.float`` while string columns with missing values are converted to object columns with ``numpy.nan`` values to indicate missing or masked data. Therefore, one cannot always round-trip between `Table` and `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd_2mass = t_2mass.to_pandas()\n",
    "pd_2mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_pd = Table.from_pandas(pd_2mass)\n",
    "t_pd.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of why this might be useful, Pandas can import/export Excel files (which Astropy's io does *not* support), and this provides a way to get such data into `astropy` Tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_2mass.to_excel(\"2mass.xls\", index=False)\n",
    "excel_data = Table.from_pandas(pd.read_excel(\"2mass.xls\"))\n",
    "excel_data.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` has a built-in `plot()` method which is handy for quick-n-dirty visualization of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd_2mass.plot.scatter('j_m', 'h_m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "*****\n",
    "\n",
    "# Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, read in the two data files representing the master source list and observations source list.  The fields for the two tables are respectively documented in:\n",
    "\n",
    "- [master_sources](http://cxc.harvard.edu/csc/columns/master.html)\n",
    "- [obs_sources](http://cxc.harvard.edu/csc/columns/persrc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master_sources = Table.read('cdfs_master_sources.fits')\n",
    "obs_sources = Table.read('cdfs_obs_sources.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`master_sources`**\n",
    "\n",
    "Each distinct X-ray source identified on the sky is represented in the catalog by a single \"master source\" entry and one or more \"source observation\" entries, one for each observation in which the source has been detected. The master source entry records the best estimates of the properties of a source, based on the data extracted from the set of observations in which the source has been detected.  The subset of fields in our exercise table file are:\n",
    "\n",
    "Name | Description\n",
    "------ | ------------\n",
    "msid  | Master source ID\n",
    "name  | Source name in the Chandra catalog\n",
    "ra  | Source RA (deg)\n",
    "dec | Source Dec (deg)\n",
    "\n",
    "**`obs_sources`**\n",
    "\n",
    "The individual source entries record all of the properties about a detection extracted from a single observation, as well as associated file-based data products, which are observation-specific.  The subset of fields in our exercise table file are:\n",
    "\n",
    "Name | Description\n",
    "------ | ------------\n",
    "obsid | Observation ID\n",
    "obi | Observation interval\n",
    "targname | Target name\n",
    "gti_obs | Observation date\n",
    "flux_aper_b | Broad band (0.5 - 7 keV) flux (erg/cm2/sec)\n",
    "src_cnts_aper_b | Broad band source counts\n",
    "ra_b | Source RA (deg)\n",
    "dec_b | Source Dec (deg)\n",
    "livetime | Observation duration (sec)\n",
    "posid | Position ID\n",
    "theta | Off-axis angle (arcmin)\n",
    "msid | Master source ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data\n",
    "Do the following to explore the two tables:\n",
    "\n",
    "- Display the data for each table in IPython notebook using the normal way of showing the value of a variable.\n",
    "- Get a list of the column names for each table.  *Hint*: use `<TAB>` completion to easily discover all the attributes and methods, e.g. type `master_sources.` and then hit the `<TAB>` key.\n",
    "- Find the length of each table.\n",
    "- Find the column datatypes for each table.\n",
    "\n",
    "Normally one displays a table in IPython notebook by entering the variable name in a cell and pressing `shift-Enter`.  In a terminal session the default method is using something like `print(my_table)`.  In both cases the `Table` object prefers to display only a screenful of data to prevent having a zillion lines of output if the table is huge.  If you really want to see all the data you can use the [Table.pprint](http://astropy.readthedocs.org/en/stable/api/astropy.table.Table.html#astropy.table.Table.pprint) method. If you are using a Jupyter notebook interface, try the `show_in_notebook()` method.\n",
    "\n",
    "- Display all the rows of the `master_sources` table using its `pprint()` method.\n",
    "- If you are working in a regular terminal window (not IPython notebook), try the `more()` method as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying tables\n",
    "For our analysis we don't actually need the `obi` (observation interval) column in the `obs_sources` table.\n",
    "\n",
    "- Remove the `obi` column from the `obs_sources` table.\n",
    "\n",
    "The `gti_obs` column name is a bit obscure (GTI is a good time interval, FWIW).\n",
    "\n",
    "- Rename the `gti_obs` column to `obs_date`.\n",
    "\n",
    "It would be nice to have a count rate in addition to the source counts.\n",
    "\n",
    "- Add a new column `src_rate_aper_b` which is the source counts divided by observation duration in sec.\n",
    "\n",
    "Some of the sources have a negative net flux in the broad band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the observation source data\n",
    "For each source detected in an individual observation (in the `obs_sources` table), let's look at the source flux values.\n",
    "\n",
    "- Use the matplotlib [`hist()`]( http://matplotlib.org/api/pyplot_api.html?highlight=pyplot.hist#matplotlib.pyplot.hist) function to make a histogram of the source fluxes.  Since the fluxes vary by orders of magnitude,\n",
    "  use the `numpy.log10` to put the fluxes in log space.\n",
    "\n",
    "- Also make the same plot but using only sources within 4 arcmin of the center.  *HINT*: use a boolean mask to select values of `theta` that are less than 4.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the master_sources and obs_sources tables\n",
    "\n",
    "The `master_sources` and `obs_sources` tables share a common `msid` column. What we now want is to join the master RA and Dec positions and master source names with the individual observations table.\n",
    "\n",
    "- Use the [table.join()](http://astropy.readthedocs.org/en/stable/table/operations.html#join) function to make a single table called `sources` that has the master RA, Dec, and name included for each observation source.\n",
    "\n",
    "*HINT*: the defaults for `keys` and `join_type='inner'`  are correct in this case, so the simplest possible call to `join()` will work!\n",
    "\n",
    "- *Intermediate*: Is the length of the new `sources` the same as `obs_sources`?  What happened?\n",
    "\n",
    "- *Advanced*: Make a scatter plot of the RA (x-axis) and Dec (y-axis) difference between the master source position and the observation source position.  You'll need to use `coordinates`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped properties of `sources`\n",
    "\n",
    "Finally, we can look at the variability properties of sources in the CDFS using the [`group_by()`](http://astropy.readthedocs.org/en/stable/table/operations.html#id2) functionality.  \n",
    "\n",
    "This method makes a new table in which all the sources with identical master ID are next to each other.\n",
    "\n",
    "- Make a new table `g_sources` which is the `sources` table grouped by the `msid` key using the `group_by()` method.\n",
    "\n",
    "The `g_sources` table is just a regular table with all the `sources` in a particular order.  The attribute `g_sources.groups` is an object that provides access to the `msid` sub-groups.  You can access the $i^{th}$ group with `g_sources.groups[i]`.\n",
    "\n",
    "In addition the `g_sources.groups.indices` attribute is an array with the indicies of the group boundaries.\n",
    "\n",
    "- Using `np.diff()` find the number of repeat observations of each master sources.  *HINT*: use the indices, Luke.\n",
    "- Print the 50th group and note which columns are the same for all group members and which are different.  Does this make sense?  In these few observations how many different target names were provided by observers?\n",
    "\n",
    "#### Aggregation\n",
    "\n",
    "The real power of grouping comes in the ability to create aggregate values for each of the groups, for instance the mean flux for each unique source.  This is done with the [`aggregate()`](http://astropy.readthedocs.org/en/stable/table/operations.html#aggregation) method, which takes a function reference as its input.  This function must take as input an array of values and return a single value.\n",
    "\n",
    "Aggregate returns a new table that has a length equal to the number of groups.\n",
    "\n",
    "- Compute the mean of all columns for each unique source (i.e. each group) using `aggregate` and the `np.mean` function.  Call this table `g_sources_mean`.\n",
    "- Notice that aggregation cannot form a mean for certain columns and these are dropped from the output.  Use the `join()` function to restore the `master_sources` information to `g_sources_mean`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting Tables and FITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While FITS *image* file access is discussed in another tutorial file, here we consider the interaction of these two: Loading a FITS table and interacting with it as an Astropy Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftab = fits.open('table_example.fits')\n",
    "ftab[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is not an `astropy.io.fits` table, *not* an Astropy Table like in the examples above. In general the Astropy Table interface is substantially easier to work with, so you'll usually want to just convert the fits table into an Astropy table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = Table(ftab[1].data)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Astropy includes a \"unified I/O\" architecture that makes it possible to effectively do this even without using `io.fits` directly at all.  This is usually the easiest approach for simple FITS files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = Table.read('table_example.fits')\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in fact you can do the same to *write* a fits table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab.write('test_write.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Writing ASCII Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equally (if not more) common interchange format in Astronomy is simple ASCII files.  `astropy` provides a large set of ASCII file readers that will read a variety of obscure astronomy formats.  While these are actually *implemented* in the `astropy.io.ascii` sub-package, in general it is easier to use the \"unified\" I/O to read these directly as tables, like in the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Table.read('example.dat', format='ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Table.read('example.csv', format='ascii.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the reader is often smart enough to determine the type of ASCII file even if you don't specify it (i.e. the `'ascii.csv'` in the above example).  For example, an IPAC format file can be read simply by doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Table.read('example.ipac', format='ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no need to specify `ascii.ipac`.\n",
    "\n",
    "The same machinery can also be used to *write* ascii files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab.write('ascii_out.dat', format='ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the above is often sufficient, it's important to know that the base-line format does *not* support quite a few of the \"advanced\" features, like inclusion of units.  To do that you'll likely want to use the astropy table \"enhanced\" CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab.write('ascii_out.ecsv', format='ascii.ecsv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
